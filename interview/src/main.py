# main.py â€” ì„œë¹„ìŠ¤ìš© ìµœì¢…ë³¸
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from contextlib import asynccontextmanager
from typing import Optional, Literal
import os, uuid, shutil

from stt.corrector import correct_transcript
from interview.model import InterviewState
from stt.transcriber import convert_to_wav, transcribe_audio
from interview.graph import graph_app
from utils.chroma_setup import reset_chroma, get_collections, reset_interview  # âœ… ë³€ê²½

# âœ… ì•± ìƒëª…ì£¼ê¸°: ê°œë°œì—ì„œë§Œ ì „ì—­ ì´ˆê¸°í™” + ì»¬ë ‰ì…˜ ì¤€ë¹„
@asynccontextmanager
async def lifespan(app: FastAPI):
    if os.getenv("CHROMA_RESET_ON_START", "0") == "1":
        reset_chroma()
    # EFê°€ ë¶™ì€ ì»¬ë ‰ì…˜ì„ ë¯¸ë¦¬ ì—´ì–´ ì´ˆê¸°í™”(ì•ˆ ì—´ì–´ë„ ì‘ë™ì€ í•¨)
    app.state.qa_questions, app.state.qa_answers, app.state.qa_feedback = get_collections()
    yield

app = FastAPI(lifespan=lifespan)

# âœ… CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

UPLOAD_DIR = "temp"
os.makedirs(UPLOAD_DIR, exist_ok=True)

def _temp_path(name: str) -> str:
    return os.path.join(UPLOAD_DIR, name)

# âœ… ì„¸ì…˜ ìƒíƒœ ì €ì¥ (ë©”ëª¨ë¦¬)
session_state = {}

# âœ… ì²« ì§ˆë¬¸ ìš”ì²­ìš© Request ëª¨ë¸
class StateRequest(BaseModel):
    ocrText: str                               # OCR ê²°ê³¼ í…ìŠ¤íŠ¸
    career: Optional[str] = None
    interviewType: Optional[str] = None
    job: str
    level: Literal["ìƒ", "ì¤‘", "í•˜"] = "ì¤‘"
    language: Literal["KOREAN", "ENGLISH"] = "KOREAN"
    seq: int = 1
    interviewId: str
    count: int = 0                          # 0ì´ë©´ ë…¸ë“œì—ì„œ ê¸°ë³¸ ë¡œì§(ìµœëŒ€ 20)

@app.post("/first-ask")
async def first_ask(payload: StateRequest, request: Request):
    print("ğŸ“¦ [payload]:", payload.model_dump())
    try:
        # âœ… ì´ ì¸í„°ë·°ì˜ ê¸°ì¡´ ë°ì´í„°ë§Œ ì´ˆê¸°í™” (ìš´ì˜ ì•ˆì „)
        reset_interview(payload.interviewId)

        # âœ… ì´ˆê¸° ìƒíƒœ êµ¬ì„±
        state = InterviewState(
            interviewId=payload.interviewId,
            job=payload.job,
            ocrText=payload.ocrText,
            career=payload.career,
            interviewType=payload.interviewType,
            level=payload.level,
            language=payload.language,
            seq=payload.seq or 1,
            count=payload.count,
            options_locked=False,
            # ì´ˆê¸°í™”
            question=[],
            answer=[],
            last_answer=None,
            keepGoing=True, 
            step=0,
        )

        # âœ… ê·¸ë˜í”„ ì‹¤í–‰ (first_question_node ë‚´ë¶€ì—ì„œ save_question í˜¸ì¶œ)
        result = graph_app.invoke(state.model_dump())
        if isinstance(result, dict):
            result = InterviewState(**result)

        # âœ… ì„¸ì…˜ ìºì‹œ ê°±ì‹ 
        session_state[payload.interviewId] = result

        return {
            "interviewId": payload.interviewId,
            "interview_question": (result.question[-1] if result.question else "")
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# âœ… STT ê¸°ë°˜ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±
@app.post("/stt-ask")
async def stt_ask(
    file: UploadFile = File(...),
    interviewId: str = Form(...),
    seq: int | None = Form(None),   # â† í•˜ìœ„ í˜¸í™˜ìš©(ë¬´ì‹œ)
    question: str = Form(None),     # âœ… (ì˜µì…˜) ë™ì  ëª¨ë“œìš© ì§ˆë¬¸
):
    # 1) ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°
    state = session_state.get(interviewId)
    if not state:
        raise HTTPException(status_code=404, detail="ë©´ì ‘ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. /first-askë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

    # 2) íŒŒì¼ ì €ì¥ + STT ë³€í™˜
    ext = (file.filename or "uploaded").split(".")[-1].lower()
    if ext not in ["mp4", "webm", "wav", "m4a", "mp3"]:
        raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
    in_path = _temp_path(f"{uuid.uuid4().hex}.{ext}")
    with open(in_path, "wb") as f:
        shutil.copyfileobj(file.file, f)

    wav_path = _temp_path(f"{uuid.uuid4().hex}.wav")
    convert_to_wav(in_path, wav_path)
    raw = transcribe_audio(wav_path)
    corrected = correct_transcript(raw) or raw

    # 3) ë‹µë³€ ì—…ë°ì´íŠ¸ (â†’ DB ì €ì¥ì€ answer_nodeì—ì„œ ì²˜ë¦¬ë¨)
    state.last_answer = corrected
    if not hasattr(state, "answer"):
        state.answer = []
    state.answer.append(corrected)

    # âœ… 3-1) ë™ì  ëª¨ë“œ(count=0)ì¼ ë•Œë§Œ ì„ì‹œ ì§ˆë¬¸ ë³´ê´€
    if getattr(state, "count", 0) == 0 and question:
        # DBì—ëŠ” ì €ì¥í•˜ì§€ ì•Šê³ , stateì—ë§Œ ì„ì‹œ ì €ì¥
        state.last_question_for_dynamic = question
        print(f"ğŸ“ [stt-ask] ë™ì  ëª¨ë“œìš© ì§ˆë¬¸ ì €ì¥: {question}")

    # 4) ê·¸ë˜í”„ ì‹¤í–‰ (ë¶„ì„ â†’ keepgoing â†’ next_question)
    result = graph_app.invoke(state.model_dump())
    if isinstance(result, dict):
        result = InterviewState(**result)

    session_state[interviewId] = result

    # 5) ì¶œë ¥ìš© seq & ì¢…ë£Œ ì—¬ë¶€
    seq_out = getattr(result, "step", None)
    if seq_out is None:
        seq_out = getattr(result, "seq", None)
    if seq_out is None:
        seq_out = 1

    analysis = result.last_analysis if hasattr(result, "last_analysis") else {}

    return {
        "interviewId": interviewId,
        "seq": seq_out,
        "interview_answer": corrected,
        "interview_answer_good": analysis.get("good", ""),
        "interview_answer_bad": analysis.get("bad", ""),
        "score": analysis.get("score", 0),
        "new_question": result.question[-1] if getattr(result, "question", None) else "",
        "keepGoing": getattr(result, "keepGoing", True)
    }