import re, math, json
from typing import Optional, List, Dict, Any
from utils.chroma_setup import get_collections, EF

# ê°™ì€ EF/ê²½ë¡œë¥¼ ì“°ëŠ” ì»¬ë ‰ì…˜ í•¸ë“¤ ê³µìœ 
# (ì•± ì‹œì‘ ì‹œ lifespanì—ì„œ reset_chroma() ì´í›„ get_collections()ê°€ 1íšŒ í˜¸ì¶œë¼ ìˆìœ¼ë©´ ë” ì¢‹ì•„ìš”)
_question, _answers, _feedback = get_collections()

def _norm(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip().lower())

def _tolist(x):
    # numpy.ndarray -> list, ê·¸ ì™¸ëŠ” ê·¸ëŒ€ë¡œ
    try:
        return x.tolist()  # ndarrayë©´ ê°€ëŠ¥
    except Exception:
        return x

def _first_inner_list(x):
    """
    xê°€ [[...]] ë˜ëŠ” ndarray([[...]]) í˜•íƒœë©´ ë‚´ë¶€ 1ì°¨ ë¦¬ìŠ¤íŠ¸ë¥¼ êº¼ë‚´ê³ ,
    ê·¸ ì™¸ë©´ ë¦¬ìŠ¤íŠ¸ ìì²´ë¥¼ ë°˜í™˜. ë¹ˆê°’/ë¹„ë¦¬ìŠ¤íŠ¸ë©´ [].
    """
    x = _tolist(x)
    if not isinstance(x, list):
        return []
    if x and isinstance(x[0], (list, tuple)):
        return list(x[0])
    return x

def _cosine(a, b) -> float:
    num = sum(x*y for x, y in zip(a, b))
    den = math.sqrt(sum(x*x for x in a)) * math.sqrt(sum(y*y for y in b))
    return num / (den + 1e-9)

# -----------------------
# ì €ì¥ ìœ í‹¸ (ë©”íƒ€ + ê²°ì •ì  ID)
# -----------------------
def save_question(
    interviewId: str,
    seq: int,
    question: str,
    job: Optional[str] = None,
    level: Optional[str] = None,
    language: Optional[str] = None,
    topic=None, 
    aspect=None
) -> None:
    _id = f"{interviewId}:{seq}:q"
    _question.add(
        ids=[_id],
        documents=[question],
        metadatas=[{
            "interviewId": interviewId,
            "seq": seq,
            "type": "question",
            "job": job or "",
            "level": level or "",
            "language": language or "",
            "topic": topic or "",
            "aspect": aspect or ""
        }],
    )

    # ğŸ”¥ documents + metadatas ë‘˜ ë‹¤ ê°€ì ¸ì˜¤ê¸°
    rows = _question.get(where={"interviewId": interviewId}, include=["documents", "metadatas"])
    docs = rows.get("documents", [])
    metas = rows.get("metadatas", [])

    print(f"ğŸ’¾ [DEBUG] í˜„ì¬ ì¸í„°ë·°({interviewId})ì— ì €ì¥ëœ ì§ˆë¬¸ë“¤:")
    for q, meta in zip(docs, metas):
        print(f"   seq={meta.get('seq')} | ì§ˆë¬¸: {q}")
        print(f"   í† í”½: {meta.get('topic')}")
        print(f"   ì¸¡ë©´(aspect): {meta.get('aspect')}")

def save_answer(
    interviewId: str,
    seq: int,
    answer: str,
    job: Optional[str] = None,
    level: Optional[str] = None,
    language: Optional[str] = None,
) -> None:
    _id = f"{interviewId}:{seq}:a"
    _answers.add(
        ids=[_id],
        documents=[answer],
        metadatas=[{
            "interviewId": interviewId,
            "seq": seq,
            "type": "answer",
            "job": job, "level": level, "language": language,
        }],
    )
# -----------------------
# ì§ˆë¬¸-ë‹µë³€-í”¼ë“œë°± í„´ ì €ì¥
def save_turn(
    interviewId: str,
    seq: int,
    question: str,
    answer: str,
    good: str = "",
    bad: str = "",
    score: int = 0,
    topic: str = "",
    aspect: str = "",
    job: Optional[str] = None,
    level: Optional[str] = None,
    language: Optional[str] = None,
    feedback: Optional[Dict[str, Any]] = None,
) -> None:
    """ì§ˆë¬¸-ë‹µë³€-í”¼ë“œë°± ì „ì²´ í„´ ì €ì¥"""
    _id = f"{interviewId}:{seq}:t"

    meta = {
        "interviewId": interviewId,
        "seq": seq,
        "type": "turn",
        "question": question or "",
        "answer": answer or "",
        "good": good or "",
        "bad": bad or "",
        "score": max(0, min(100, int(score) if isinstance(score, (int, str)) else 0)),
        "topic": topic or "",
        "aspect": aspect or "",
        "job": job or "",
        "level": level or "",
        "language": language or "",
        "feedback": json.dumps(feedback) if feedback else "",
    }

    doc = f"Q: {question}\nA: {answer}\n[Feedback] good: {good} | bad: {bad} | score: {score}"

    try:
        existed = _feedback.get(ids=[_id])
        if existed and existed.get("ids"):
            _feedback.update(
                ids=[_id],
                metadatas=[meta],
                documents=[doc],
            )
            print(f"ğŸ”„ [Turn Update] interviewId={interviewId}, seq={seq}")
            print("   ì§ˆë¬¸:", question)
            print("   ë‹µë³€:", answer)
            print("   í† í”½:", topic)
            print("   ì¸¡ë©´(aspect):", aspect)
            print("   í”¼ë“œë°±:", feedback)
            return
    except Exception:
        pass

    _feedback.add(
        ids=[_id],
        metadatas=[meta],
        documents=[doc],
    )
    print(f"ğŸ’¾ [Turn Saved] interviewId={interviewId}, seq={seq}")
    print("   ì§ˆë¬¸:", question)
    print("   ë‹µë³€:", answer)
    print("   í† í”½:", topic)
    print("   ì¸¡ë©´(aspect):", aspect)
    print("   í”¼ë“œë°±:", feedback)
# -----------------------
# ì§ˆë¬¸ ìœ ì‚¬ë„(ì„¸ì…˜ ìŠ¤ì½”í”„)
# -----------------------
def get_similar_question(
    interviewId: str,
    question: str,
    k: int = 5,
    min_similarity: float = 0.8,
    verify_all: bool = True,
) -> Dict[str, Any]:
    """
    1) KNN(top-k)ë¡œ ë¹ ë¥¸ ì²´í¬ â†’ ì„ê³„ê°’ ë„˜ìœ¼ë©´ ë°”ë¡œ similar=True
    2) (ì˜µì…˜) ì„ê³„ê°’ ë¯¸ë‹¬ì´ë©´ ì„¸ì…˜ 'ì „ì²´ ì§ˆë¬¸ ì„ë² ë”©' ì „ìˆ˜ ë¹„êµ
    return: dict(similar, top_sim, match, method, hits)
    """

    print(f"\nğŸ” [DEBUG:get_similar_question] interviewId={interviewId}")
    print(f"   â–¶ï¸ New Question: {question}")

    # ---------- 1) KNN ë¹ ë¥¸ ì²´í¬ ----------
    res = _question.query(
        query_texts=[question],
        n_results=k,
        where={"interviewId": interviewId},
        include=["documents", "distances"],
    )
    docs_raw  = res.get("documents", [])
    dists_raw = res.get("distances", [])

    docs  = _first_inner_list(docs_raw)
    dists = _first_inner_list(dists_raw)

    hits: List[Dict[str, Any]] = []
    qn = _norm(question)

    if len(docs) and len(dists):
        for doc, dist in zip(docs, dists):
            doc = "" if doc is None else str(doc)
            sim = 1.0 - float(dist)  # cosine
            if _norm(doc) == qn:  # ì™„ì „íˆ ë™ì¼í•œ ë¬¸ì¥ì€ ì œì™¸
                continue
            hits.append({"doc": doc, "sim": sim, "dist": float(dist)})

    hits.sort(key=lambda x: x["sim"], reverse=True)

    if hits:
        print("   â–¶ï¸ KNN hits:")
        for h in hits:
            print(f"      - '{h['doc']}' | sim={h['sim']:.4f}")

    if hits and hits[0]["sim"] >= min_similarity:
        print(f"âœ… KNN Top match: {hits[0]['doc']} (sim={hits[0]['sim']:.4f}) >= {min_similarity}")
        return {
            "similar": True,
            "top_sim": float(hits[0]["sim"]),
            "match": hits[0]["doc"],
            "method": "knn",
            "hits": hits,
        }

    if not verify_all:
        return {"similar": False, "top_sim": 0.0, "match": None, "method": "knn", "hits": hits}

    # ---------- 2) ì „ì²´ ì „ìˆ˜ ë¹„êµ ----------
    rows = _question.get(
        where={"interviewId": interviewId},
        include=["documents", "embeddings"],
        limit=10000, offset=0
    )
    all_docs = _tolist(rows.get("documents", [])) or []
    all_embs = _tolist(rows.get("embeddings", [])) or []

    if not all_docs:
        print("âš ï¸ No documents found for interviewId in Chroma")
        return {"similar": False, "top_sim": 0.0, "match": None, "method": "all", "hits": hits}

    qvec = EF([question])[0]
    qvec = _tolist(qvec)

    best_sim, best_doc = 0.0, None
    for doc, emb in zip(all_docs, all_embs):
        if not emb:
            continue
        emb = _tolist(emb)
        doc = "" if doc is None else str(doc)
        if _norm(doc) == qn:
            continue
        sim = _cosine(qvec, emb)
        if sim > best_sim:
            best_sim, best_doc = sim, doc

    if best_doc:
        print(f"   â–¶ï¸ Best overall match: '{best_doc}' (sim={best_sim:.4f})")

    return {
        "similar": best_sim >= min_similarity,
        "top_sim": float(best_sim),
        "match": best_doc,
        "method": "all",
        "hits": hits,
    }

# -----------------------
# í”¼ë“œë°± ì €ì¥/ì¡°íšŒ
# -----------------------
def save_feedback(
    interviewId: str,
    seq: int,
    good: str,
    bad: str,
    score: int,
    extra_meta: Optional[Dict[str, Any]] = None,
) -> None:
    """í•œ ì§ˆë¬¸/ë‹µë³€ë‹¹ í”¼ë“œë°± 1ê±´ â†’ ê°™ì€ idë©´ ì—…ë°ì´íŠ¸"""
    _id = f"{interviewId}:{seq}:f"
    score = max(0, min(100, int(score) if isinstance(score, (int, str)) else 0))
    meta = {
        "interviewId": interviewId,
        "seq": seq,
        "good": good,
        "bad": bad,
        "score": score,
    }
    if extra_meta:
        meta.update(extra_meta)

    try:
        existed = _feedback.get(ids=[_id])
        if existed and existed.get("ids"):
            _feedback.update(
                ids=[_id],
                metadatas=[meta],
                documents=[f"good:{good}\nbad:{bad}\nscore:{score}"],
            )
            return
    except Exception:
        pass

    _feedback.add(
        ids=[_id],
        metadatas=[meta],
        documents=[f"good:{good}\nbad:{bad}\nscore:{score}"],
    )

def list_feedback(interviewId: str) -> List[Dict[str, Any]]:
    res = _feedback.get(
        where={"interviewId": interviewId},
        include=["metadatas"],
        limit=10000,
        offset=0,
    )
    items = res.get("metadatas") or []
    items.sort(key=lambda x: x.get("seq", 0))
    return items
