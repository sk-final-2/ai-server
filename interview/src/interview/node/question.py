from interview.model import InterviewState, ResumeItem
from interview.node.rules import system_rule
from utils.chroma_qa import save_question, get_similar_question
from interview.config import llm
from langchain_core.prompts import ChatPromptTemplate
from utils.chroma_setup import reset_interview
from interview.node.rules import validate_language_text, clean_question
from interview.prompts.topic_prompts import get_topic_prompt
from utils.question_filter import init_topics_for_session
import json,re, random

def extract_json_array(text: str):
    try:
        match = re.search(r"\[.*\]", text, re.DOTALL)
        if not match:
            return []
        return json.loads(match.group(0))
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        print("âš ï¸ ì›ë³¸ ì‘ë‹µ:", text)
        return []
    
def extract_topics_node(state):
    resume_text = state.resume or ""
    topic_desc = state.topics[state.current_topic_index].get("desc", "") if state.topics else ""
    sum_prompt = get_topic_prompt(state.interviewType, resume_text, state.language, desc=topic_desc)

    sum_resp = llm.invoke(sum_prompt)
    raw_sum = sum_resp.content if hasattr(sum_resp, "content") else str(sum_resp)
    print("ğŸ“„ ìì†Œì„œ ê¸°ë°˜ í† í”½:", raw_sum)
    try:
        match = re.search(r'\[.*\]', raw_sum, re.DOTALL)
        json_str = match.group(0) if match else None
        parsed = json.loads(json_str) if json_str else []

        fixed = []
        for item in parsed:
            if isinstance(item, dict):
                fixed.append(
                    ResumeItem(
                        key=item.get("key") or item.get("theme") or item.get("topic") or "",
                        desc=item.get("desc") or item.get("value") or item.get("description") or ""
                    )
                )
            else:
                fixed.append(ResumeItem(key=str(item), desc=""))
        state.resume_summary = fixed
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        print("âš ï¸ ì›ë³¸ ì‘ë‹µ:", raw_sum)
        state.resume_summary = []

    # --- âœ… desc ì¤‘ì‹¬ìœ¼ë¡œ topic ì„¸íŒ… ---
    state.topics = [
        {"name": item.key, "asked": 0, "max_questions": 3}
        for item in state.resume_summary if item.desc
    ]
    state.topics = init_topics_for_session(state.topics, 3, 5)
    state.current_topic_index = 0 if state.topics else None

    print("ğŸ“Œ Resume summary:", state.resume_summary)
    print("PARSED TOPICS (desc ê¸°ë°˜):", [t["name"] for t in state.topics])
    print("âœ… state.topics ì„¸íŒ… ì™„ë£Œ:", state.topics)
    return state

def setup_default_topics_node(state: InterviewState) -> InterviewState:
    try:
        if isinstance(state, dict):
            state = InterviewState(**state)

        job = (state.job or "ì›¹ ê°œë°œì").strip()
        lang_code = state.language or "KOREAN"
        interview_type = state.interviewType or "MIXED"
        level = state.level or "ì¤‘"

        sys_prompt = system_rule(state)

        prompt = f"""
        {sys_prompt}

        ì§€ì› ì§ë¬´ëŠ” '{job}'ì´ë‹¤. ìê¸°ì†Œê°œì„œëŠ” ì œê³µë˜ì§€ ì•Šì•˜ë‹¤.
        ì´ ì§ë¬´ì™€ ê´€ë ¨ëœ ë©´ì ‘ í† í”½ì„ 3~5ê°œ ë½‘ì•„ë¼.

        ì¡°ê±´:
        - JSON ë°°ì—´ë¡œ ì¶œë ¥
        - ê° í•­ëª©ì€ {{"key": "í† í”½ëª…", "desc": "ì„¤ëª…"}} êµ¬ì¡°
        - {interview_type} ìœ í˜•ì— ë§ë„ë¡ í† í”½ ë‹¤ì–‘ì„± ë°˜ì˜
        - ë‚œì´ë„ {level}ì— ë§ì¶° ì‰¬ìš´ ê²ƒë¶€í„° ì‹¬í™”ê¹Œì§€ í¬í•¨
        - { 'í•œêµ­ì–´' if lang_code == 'KOREAN' else 'ì˜ì–´'} ì§ˆë¬¸ì— ì í•©í•œ ì£¼ì œ
        """

        resp = llm.invoke(prompt)
        raw = resp.content if hasattr(resp, "content") else str(resp)
        topics = extract_json_array(raw)

        state.topics = [
            {"name": t.get("key", ""), "asked": 0, "max_questions": 3}
            for t in topics if isinstance(t, dict) and t.get("key")
        ]
        state.topics = init_topics_for_session(state.topics, 3, 5)
        state.current_topic_index = 0 if state.topics else None

        print("âœ… [setup_default_topics_node] topics:", state.topics)
        return state

    except Exception as e:
        print("âŒ [setup_default_topics_node ì˜¤ë¥˜]:", str(e))
        state.topics = []
        state.current_topic_index = None
        return state
#------------------------------------------------------------------------------------------------------------------------------    
def first_question_node(state: InterviewState) -> InterviewState:
    """ğŸ¯ ì²« ì§ˆë¬¸ ìƒì„± ë…¸ë“œ (í† í”½ ê¸°ë°˜ + fallback + ì–¸ì–´ ë³´ì •)"""
    try:
        if isinstance(state, dict):
            state = InterviewState(**state)

        idx = state.current_topic_index or 0
        job = (state.job or "").strip() or "ì›¹ ê°œë°œì"
        state.job = job
        lang_code = state.language or "KOREAN"

        print("\n======================")
        print("ğŸ¯ [first_question_node] ì§„ì…")
        print(f"ğŸ’¼ ì§€ì› ì§ë¬´: {job}")
        print("======================")
        print(f"ğŸ§­ INTERVIEW TYPE: {state.interviewType}")
        print(f"ğŸ§­ SELECTED ASPECT: {state.aspect}")
        interviewId = state.interviewId
        if not interviewId:
            raise ValueError("âŒ interviewIdê°€ ì—†ìŠµë‹ˆë‹¤.")

        # --- âœ… í† í”½/ì¸¡ë©´ ì´ˆê¸°í™” ---
        if state.topics and idx < len(state.topics):
            state.topic = state.topics[idx]["name"]
            topic_desc = state.topics[idx].get("desc", "")
        else:
            state.topic = None
            topic_desc = ""

        if state.aspects:
            state.aspect = random.choice(state.aspects)
        else:
            state.aspect = None

        print(f"ğŸ“„ ì„ íƒëœ í† í”½: {state.topic}")
        print(f"ğŸ“„ ì„ íƒëœ ì¸¡ë©´(aspect): {state.aspect}")
        current_subtype = getattr(state, "subtype", None)

        # --- í”„ë¡¬í”„íŠ¸ ìƒì„± ---
        if state.topic:  # âœ… topic ê¸°ë°˜
            prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", system_rule(state)),
                    ("user",
                        "ì§€ì› ì§ë¬´: {{ job }}\n"
                        "í˜„ì¬ í† í”½: {{ cur_topic }}\n"
                        "í˜„ì¬ í† í”½ ì„¤ëª…: {{ topic_desc }}\n"
                        "ì°¸ê³  ê´€ì (aspect): {{ subtype }}\n\n"
                        "ì§€ì‹œì‚¬í•­:"
                        "- ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ë©´ì ‘ì—ì„œ ì‚¬ìš©í•  ì§ˆë¬¸ì„ ìƒì„±í•´ë¼.\n"
                        "- ë„ˆëŠ” ê¸°ì—… ë©´ì ‘ê´€ì´ë‹¤. í•­ìƒ ì‹¤ì œ ì±„ìš© ë©´ì ‘ì—ì„œ ì‚¬ìš©í•  ë²•í•œ ì§ˆë¬¸ì„ í•œë‹¤.\n"
                        "- {{cur_topic}}ì€ ê·¸ëŒ€ë¡œ ë¬¸ì¥í™”í•˜ì§€ ë§ ê²ƒ (ë‹¨ìˆœ í‚¤ì›Œë“œì„)\n"
                        "- ë°˜ë“œì‹œ {{cur_topic}}ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì§ˆë¬¸í•  ê²ƒ\n"
                        "- ë‹¨, {{ topic_desc }} ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ì´ê³  ìƒí™©ì— ë§ê²Œ ì‘ì„±í•˜ë¼\n"
                        "- ë°˜ë“œì‹œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±"
                    )
                ],
                template_format="jinja2"
            )

            variables = {
                "job": job,
                "cur_topic": state.topic,
                "topic_desc": topic_desc,
                "subtype": state.aspect or "METHOD",
            }
            messages = prompt.format_messages(**variables)   # âœ… dict ì–¸íŒ¨í‚¹
            response = llm.bind(max_tokens=200, temperature=0.2, top_p=0.8).invoke(messages)
            raw_q = (getattr(response, "content", "") or str(response)).strip()

        else:  # âŒ í† í”½ ì—†ìœ¼ë©´ ì§ë¬´/ê²½ë ¥ ê¸°ë°˜
            prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", system_rule(state)),
                    ("user",
                        "job: {{ job }}\n"
                        "career: {{ career }}\n"
                        "resume: '''{{ resume }}'''"
                    )
                ],
                template_format="jinja2"
            )
            variables = {
                "job": job,
                "career": state.career or "ë¯¸ê¸°ì¬",
                "resume": (state.ocrText or getattr(state, "resume", "") or "").strip()[:800],
            }
            messages = prompt.format_messages(**variables)   # âœ… dict ì–¸íŒ¨í‚¹
            response = llm.bind(max_tokens=200, temperature=0.2, top_p=0.8).invoke(messages)
            raw_q = (getattr(response, "content", "") or "").strip()

        # --- ì–¸ì–´ ë³´ì • ---
        question = raw_q
        if not validate_language_text(question, lang_code):
            strong = (
                "Respond ONLY in English. One sentence only."
                if lang_code == "ENGLISH"
                else "ì˜¤ì§ í•œêµ­ì–´ë¡œ í•œ ë¬¸ì¥ë§Œ ë‹µí•˜ë¼."
            )
            fix_prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", strong),
                    ("user", "Rewrite as ONE interview question only (no preface/numbering/quotes): {{ q }}")
                ],
                template_format="jinja2"
            )
            messages = fix_prompt.format_messages(q=question)   # âœ… í‚¤ì›Œë“œ ì¸ì ë°©ì‹
            response = llm.bind(max_tokens=200, temperature=0).invoke(messages)
            question = (getattr(response, "content", "") or "").strip()

        # --- ìµœì¢… í›„ì²˜ë¦¬ ---
        question = clean_question(question)

        # fallback ì§ˆë¬¸
        if not question:
            question = (
                f"{job} ì—­í• ì—ì„œ ìµœê·¼ ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸ì™€ ë³¸ì¸ ê¸°ì—¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                if lang_code == "KOREAN"
                else f"For the {job} role, describe your most recent project and your specific contribution."
            )

        # âœ… ìƒíƒœ ì—…ë°ì´íŠ¸
        seq = int(state.seq or 1)
        state.seq = seq
        if seq == 1:
            reset_interview(interviewId)

        save_question(
            state.interviewId,
            seq,
            question,
            job=state.job,
            level=state.level,
            language=state.language,
            topic=state.topic or "",
            aspect=state.aspect or "",
            subtype=current_subtype or "",
        )

        state.question = question
        state.questions.append(question)
        state.step = (state.step or 0) + 1

        if state.topic:
            state.topics[idx]["asked"] = int(state.topics[idx].get("asked", 0)) + 1
            state.last_question_for_dynamic = question

        cnt = int(state.count or 0)
        if cnt > 0 and seq >= cnt:
            state.keepGoing = False

        print("âœ… [first_question_node] ìµœì¢… ì§ˆë¬¸:", state.question)
        return state

    except Exception as e:
        print("âŒ [first_question_node ì˜¤ë¥˜ ë°œìƒ]:", str(e))
        import traceback; traceback.print_exc()
        raise e
#------------------------------------------------------------------------------------------------------------------------------    
def next_question_node(state: InterviewState) -> InterviewState:
    """â¡ï¸ ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ë…¸ë“œ (ì „í™˜/ì¿¨ë‹¤ìš´/ì¤‘ë³µ ë°©ì§€ ë³´ì™„íŒ)"""
    try:
        if isinstance(state, dict):
            state = InterviewState(**state)

        topics = getattr(state, "topics", [])
        if not topics:
            state.keepGoing = False
            return state

        cur_topic_data = topics[state.current_topic_index]
        cur_topic = cur_topic_data.get("name", "")
        topic_desc = cur_topic_data.get("desc", "") or ""
        job = (state.job or "").strip() or "ì›¹ ê°œë°œì"

        prev_q = state.questions[-1] if state.questions else ""
        prev_a = state.last_answer or (state.answer[-1] if state.answer else "")

        # ì „í™˜ ì—¬ë¶€ ì²´í¬
        just_switched = bool(getattr(state, "just_switched_topic", False))
        prev_a_for_prompt = "" if just_switched else prev_a[:800]

        # subtype ë³´ì •
        current_subtype = (getattr(state, "subtype", None) or "").strip() or "METHOD"

        # --- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ---
        followup_prompt = ChatPromptTemplate.from_messages([
            ("system", "ë„ˆëŠ” ê³µì†í•˜ê³  ê°„ê²°í•˜ê²Œ ì§ˆë¬¸í•œë‹¤."),
            ("human",
             "ì§ë¬´: {job}\n"
             "í˜„ì¬ í† í”½: {cur_topic}\n"
             "í˜„ì¬ í† í”½ ì„¤ëª…: {topic_desc}\n"
             "ì„œë¸Œíƒ€ì… íŒíŠ¸: {subtype}\n"
             "ì§ì „ ì§ˆë¬¸: {prev_q}\n"
             "ì§ì „ ë‹µë³€: {prev_a}\n\n"
             "ì§€ì‹œì‚¬í•­:"
             "- ì§ì „ ë‹µë³€ì„ ë” ê¹Šì´ íŒŒëŠ” í›„ì† ì§ˆë¬¸ 1ê°œ ìƒì„±"
             "- ë„ˆëŠ” ê¸°ì—… ë©´ì ‘ê´€ì´ë‹¤. í•­ìƒ ì‹¤ì œ ì±„ìš© ë©´ì ‘ì—ì„œ ì‚¬ìš©í•  ë²•í•œ ì§ˆë¬¸ì„ í•œë‹¤.\n"
             "- ë‹µë³€ì—ì„œ ë‚˜ì˜¨ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, í† í”½ì˜ ì„¸ë¶€ ë§¥ë½ì„ ë” ê¹Šì´ íƒìƒ‰í•˜ëŠ” ì§ˆë¬¸ì„ í•˜ë¼"
             "- AspectëŠ” ì°¸ê³ ìš©ì¼ ë¿, í† í”½ì„ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ”ë‹¤"
             "- í•œ ë¬¸ì¥ìœ¼ë¡œ, ì‹¤ì œ ë©´ì ‘ê´€ì²˜ëŸ¼ ê³µì†í•˜ê³  ê°„ê²°í•˜ê²Œ ì§ˆë¬¸í•˜ë¼")
        ])

        lateral_prompt = ChatPromptTemplate.from_messages([
            ("system", "ë„ˆëŠ” ê³µì†í•˜ê³  ê°„ê²°í•˜ê²Œ ì§ˆë¬¸í•œë‹¤."),
            ("human",
             "ì§ë¬´: {job}\n"
             "í˜„ì¬ í† í”½: {cur_topic}\n"
             "í˜„ì¬ í† í”½ ì„¤ëª…: {topic_desc}\n"
             "ì§‘ì¤‘í•  ì¸¡ë©´: {subtype}\n"
             "ì§ì „ ì§ˆë¬¸: {prev_q}\n"
             "ì§ì „ ë‹µë³€(ì„ íƒ): {prev_a}\n\n"
             "ì§€ì‹œì‚¬í•­:"
             "- ë°˜ë“œì‹œ [í˜„ì¬ í† í”½]ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ì‘ì„±í•˜ë¼"
             "- ë„ˆëŠ” ê¸°ì—… ë©´ì ‘ê´€ì´ë‹¤. í•­ìƒ ì‹¤ì œ ì±„ìš© ë©´ì ‘ì—ì„œ ì‚¬ìš©í•  ë²•í•œ ì§ˆë¬¸ì„ í•œë‹¤.\n"
             "- Aspect({subtype})ëŠ” ë³´ì¡°ì  ê°ë„ë¡œë§Œ í™œìš©í•˜ê³ , í† í”½ ìì²´ë¥¼ ëŒ€ì²´í•˜ì§€ ì•ŠëŠ”ë‹¤"
             "- ì§ì „ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ë°©í–¥ìœ¼ë¡œ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ë¼"
             "- í•œ ë¬¸ì¥ìœ¼ë¡œ, ì‹¤ì œ ë©´ì ‘ê´€ì²˜ëŸ¼ ê³µì†í•˜ê³  ê°„ê²°í•˜ê²Œ ì§ˆë¬¸í•˜ë¼")
        ])

        def clean_question(q: str) -> str:
            return (q or "").strip()

        def gen_candidate(prompt, use_prev_a: str):
            variables = {
                "job": job,
                "prev_q": prev_q,
                "prev_a": use_prev_a,
                "subtype": current_subtype,
                "cur_topic": cur_topic,
                "topic_desc": topic_desc
            }
            messages = prompt.format_messages(**variables)  # âœ… dict ì–¸íŒ¨í‚¹
            res = llm.invoke(messages)
            text = (getattr(res, "content", "") or str(res)).strip()
            return clean_question(text)

        # ------------------------------
        # [C] í›„ë³´ ìƒì„±
        # ------------------------------
        candidates = []
        if not just_switched:
            for _ in range(3):
                candidates.append(("FOLLOWUP", gen_candidate(followup_prompt, prev_a_for_prompt)))
        for _ in range(2):
            candidates.append(("LATERAL", gen_candidate(lateral_prompt, prev_a_for_prompt)))

        # ------------------------------
        # [D] í›„ë³´ ìŠ¤ì½”ì–´ë§
        # ------------------------------
        best_q, best_kind, best_score = None, None, -1.0
        for kind, text in candidates:
            if not text or len(text) < 5:
                continue

            # âœ… ì¤‘ë³µ ì²´í¬
            check = get_similar_question(
                state.interviewId,
                text,
                k=3,  # ìµœê·¼ 3ê°œ ì§ˆë¬¸ê³¼ ë¹„êµ
                min_similarity=0.85,
                verify_all=True,
                subtype=state.subtype or "METHOD",
                job=state.job,
            )
            if check.get("similar"):
                print(f"âš ï¸ ì¤‘ë³µ ì§ˆë¬¸ ì œê±°ë¨: {text}")
                continue

            score = 0.7 if (just_switched and kind == "LATERAL") else (0.55 if kind == "FOLLOWUP" else 0.5)
            if score > best_score:
                best_q, best_kind, best_score = text, kind, score

        final_q = best_q or "ë°©ê¸ˆ ì„¤ëª…í•˜ì‹  ë‚´ìš©ì—ì„œ ê°€ì¥ ì¸ìƒì ì¸ ë¶€ë¶„ì„ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
        print(f"âœ… [ì„ ì •] kind={best_kind}, score={best_score}, q={final_q}")

        # ------------------------------
        # [E] ìƒíƒœ ì—…ë°ì´íŠ¸ & ì €ì¥
        # ------------------------------
        state.question = final_q
        state.questions.append(final_q)

        cur_topic_data["asked"] = int(cur_topic_data.get("asked", 0)) + 1
        state.seq = (state.seq or 0) + 1
        state.step = (state.step or 0) + 1

        # âœ… ì €ì¥ (í•­ìƒ ìµœì‹  í† í”½ëª… ê¸°ì¤€)
        final_topic_name = topics[state.current_topic_index]["name"]
        state.subtype = (getattr(state, "subtype", None) or current_subtype or "METHOD")

        save_question(
            state.interviewId,
            state.seq,
            state.question,
            job=state.job,
            level=state.level,
            language=state.language,
            topic=final_topic_name,
            aspect=state.aspect,
            subtype=state.subtype,
        )

        # ------------------------------
        # [F] ì „í™˜ ì¡°ê±´ ê²€ì‚¬
        # ------------------------------
        if cur_topic_data.get("asked", 0) >= cur_topic_data.get("max_questions", 3):
            print(f"ğŸ›‘ '{cur_topic_data['name']}' í† í”½ ì§ˆë¬¸ {cur_topic_data['asked']}ê°œ ì™„ë£Œ â†’ ë‹¤ìŒ í† í”½")
            state.current_topic_index += 1
            state.bridge_done = False
            if state.current_topic_index < len(topics):
                state.topic = topics[state.current_topic_index]["name"]
                state.aspect = random.choice(state.aspects) if state.aspects else None
                state.just_switched_topic = True
                state.last_bridge_turn = state.seq
                print(f"ğŸ“Œ [next_question_node] í† í”½ ì „í™˜ ì™„ë£Œ â†’ {state.topic}")
            else:
                state.keepGoing = False

        return state

    except Exception as e:
        print("âŒ [next_question_node ì˜ˆì™¸]:", str(e))
        import traceback; traceback.print_exc()
        state.keepGoing = False
        return state