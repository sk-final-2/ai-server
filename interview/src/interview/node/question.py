from interview.question_bank import FALLBACK_POOL
from interview.model import InterviewState, ResumeItem
from interview.node.rules import system_rule
from utils.chroma_qa import save_question, get_similar_question
from utils.question_filter import is_redundant
from interview.config import llm
from langchain_core.prompts import ChatPromptTemplate
from utils.chroma_setup import reset_interview
from interview.node.rules import validate_language_text, clean_question, validate_question
from interview.prompts.topic_prompts import get_topic_prompt
import json,re

def extract_json_array(text: str):
    try:
        match = re.search(r"\[.*\]", text, re.DOTALL)
        if not match:
            return []
        return json.loads(match.group(0))
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        print("âš ï¸ ì›ë³¸ ì‘ë‹µ:", text)
        return []
    
def extract_topics_node(state):
    resume_text = state.resume or ""
    sum_prompt = get_topic_prompt(state.interviewType, resume_text, state.language)

    sum_resp = llm.invoke(sum_prompt)
    raw_sum = sum_resp.content if hasattr(sum_resp, "content") else str(sum_resp)
    print("ğŸ“„ ìì†Œì„œ ê¸°ë°˜ í† í”½:", raw_sum)
    try:
        match = re.search(r'\[.*\]', raw_sum, re.DOTALL)
        json_str = match.group(0) if match else None
        parsed = json.loads(json_str) if json_str else []

        fixed = []
        for item in parsed:
            if isinstance(item, dict):
                fixed.append(
                    ResumeItem(
                        key=item.get("key") or item.get("theme") or item.get("topic") or "",
                        desc=item.get("desc") or item.get("value") or item.get("description") or ""
                    )
                )
            else:
                fixed.append(ResumeItem(key=str(item), desc=""))
        state.resume_summary = fixed
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        print("âš ï¸ ì›ë³¸ ì‘ë‹µ:", raw_sum)
        state.resume_summary = []

    # --- âœ… desc ì¤‘ì‹¬ìœ¼ë¡œ topic ì„¸íŒ… ---
    state.topics = [
        {"name": item.key, "asked": 0, "max_questions": 3}
        for item in state.resume_summary if item.desc
    ]
    state.current_topic_index = 0 if state.topics else None

    print("ğŸ“Œ Resume summary:", state.resume_summary)
    print("PARSED TOPICS (desc ê¸°ë°˜):", [t["name"] for t in state.topics])
    print("âœ… state.topics ì„¸íŒ… ì™„ë£Œ:", state.topics)
    return state

def setup_default_topics_node(state: InterviewState) -> InterviewState:
    try:
        if isinstance(state, dict):
            state = InterviewState(**state)

        job = (state.job or "ì›¹ ê°œë°œì").strip()
        lang_code = state.language or "KOREAN"
        interview_type = state.interviewType or "MIXED"
        level = state.level or "ì¤‘"

        sys_prompt = system_rule(state)

        prompt = f"""
        {sys_prompt}

        ì§€ì› ì§ë¬´ëŠ” '{job}'ì´ë‹¤. ìê¸°ì†Œê°œì„œëŠ” ì œê³µë˜ì§€ ì•Šì•˜ë‹¤.
        ì´ ì§ë¬´ì™€ ê´€ë ¨ëœ ë©´ì ‘ í† í”½ì„ 3~5ê°œ ë½‘ì•„ë¼.

        ì¡°ê±´:
        - JSON ë°°ì—´ë¡œ ì¶œë ¥
        - ê° í•­ëª©ì€ {{"key": "í† í”½ëª…", "desc": "ì„¤ëª…"}} êµ¬ì¡°
        - {interview_type} ìœ í˜•ì— ë§ë„ë¡ í† í”½ ë‹¤ì–‘ì„± ë°˜ì˜
        - ë‚œì´ë„ {level}ì— ë§ì¶° ì‰¬ìš´ ê²ƒë¶€í„° ì‹¬í™”ê¹Œì§€ í¬í•¨
        - { 'í•œêµ­ì–´' if lang_code == 'KOREAN' else 'ì˜ì–´'} ì§ˆë¬¸ì— ì í•©í•œ ì£¼ì œ
        """

        resp = llm.invoke(prompt)
        raw = resp.content if hasattr(resp, "content") else str(resp)
        topics = extract_json_array(raw)

        state.topics = [
            {"name": t.get("key", ""), "asked": 0, "max_questions": 3}
            for t in topics if isinstance(t, dict) and t.get("key")
        ]
        state.current_topic_index = 0 if state.topics else None

        print("âœ… [setup_default_topics_node] topics:", state.topics)
        return state

    except Exception as e:
        print("âŒ [setup_default_topics_node ì˜¤ë¥˜]:", str(e))
        state.topics = []
        state.current_topic_index = None
        return state
#------------------------------------------------------------------------------------------------------------------------------    
def first_question_node(state: InterviewState) -> InterviewState:
    """ğŸ¯ ì²« ì§ˆë¬¸ ìƒì„± ë…¸ë“œ (í† í”½ ê¸°ë°˜ + fallback + ì–¸ì–´ ë³´ì •)"""
    try:
        if isinstance(state, dict):
            state = InterviewState(**state)

        idx = state.current_topic_index or 0
        job = (state.job or "").strip() or "ì›¹ ê°œë°œì"
        state.job = job
        lang_code = state.language or "KOREAN"
        print("\n======================")
        print("ğŸ¯ [first_question_node] ì§„ì…")
        print(f"ğŸ’¼ ì§€ì› ì§ë¬´: {job}")
        print("======================")
        print(f"ğŸ§­ INTERVIEW TYPE: {state.interviewType}")
        print(f"ğŸ§­ SELECTED ASPECT: {state.aspect}")
        interviewId = state.interviewId
        if not interviewId:
            raise ValueError("âŒ interviewIdê°€ ì—†ìŠµë‹ˆë‹¤.")

        # --- âœ… í† í”½/ì¸¡ë©´ ì´ˆê¸°í™” (ì§ˆë¬¸ ìƒì„± ì „ì— ë¬´ì¡°ê±´ stateì— ì„¸íŒ…) ---
        if state.topics and idx < len(state.topics):
            state.topic = state.topics[idx]["name"]
        else:
            state.topic = None

        if state.aspects:
            state.aspect = state.aspects[state.aspect_index % len(state.aspects)]
        else:
            state.aspect = None

        print(f"ğŸ“„ ì„ íƒëœ í† í”½: {state.topic}")
        print(f"ğŸ“„ ì„ íƒëœ ì¸¡ë©´(aspect): {state.aspect}")
        current_subtype = getattr(state, "subtype", None)
        # --- í”„ë¡¬í”„íŠ¸ ìƒì„± ---
        if state.topic:  # âœ… topic ê¸°ë°˜
            prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", system_rule(state)),
                    ("user", "ì§€ì› ì§ë¬´: {{ job }}\ní† í”½: {{ topic }}\nì„¤ëª…: {{ desc }}\n\n"
                              "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ë©´ì ‘ì—ì„œ ì‚¬ìš©í•  ì§ˆë¬¸ì„ ìƒì„±í•´ë¼.\n"
                              "- {{topic}}ì€ ê·¸ëŒ€ë¡œ ë¬¸ì¥í™”í•˜ì§€ ë§ ê²ƒ (ë‹¨ìˆœ í‚¤ì›Œë“œì„)\n"
                              "- ë°˜ë“œì‹œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±\n"
                    )
                ],
                template_format="jinja2"
            )
            response = (prompt | llm).invoke({
                "job": job,
                "topic": state.topic,
                "desc": state.resume_summary[idx].desc if state.resume_summary and idx < len(state.resume_summary) else ""
            })
            raw_q = (response.content or "").strip()
        else:  # âŒ í† í”½ ì—†ìœ¼ë©´ ì§ë¬´/ê²½ë ¥ ê¸°ë°˜
            prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", system_rule(state)),
                    ("user", "job: {{ job }}\ncareer: {{ career }}\nresume: '''{{ resume }}'''")
                ],
                template_format="jinja2"
            )
            variables = {
                "job": job,
                "career": state.career or "ë¯¸ê¸°ì¬",
                "resume": (state.ocrText or getattr(state, "resume", "") or "").strip()[:800],
            }
            response = (prompt | llm.bind(max_tokens=200, temperature=0.2, top_p=0.8)).invoke(variables)
            raw_q = (response.content or "").strip()

        # --- ì–¸ì–´ ë³´ì • ---
        question = raw_q
        if not validate_language_text(question, lang_code):
            strong = (
                "Respond ONLY in English. One sentence only."
                if lang_code == "ENGLISH"
                else "ì˜¤ì§ í•œêµ­ì–´ë¡œ í•œ ë¬¸ì¥ë§Œ ë‹µí•˜ë¼."
            )
            fix_prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", strong),
                    ("user", "Rewrite as ONE interview question only (no preface/numbering/quotes): {{ q }}")
                ],
                template_format="jinja2"
            )
            question = (
                (fix_prompt | llm.bind(max_tokens=200, temperature=0))
                .invoke({"q": question})
                .content.strip()
            )

        # --- ìµœì¢… í›„ì²˜ë¦¬ ---
        question = clean_question(question)

        # fallback ì§ˆë¬¸
        if not question:
            question = (
                f"{job} ì—­í• ì—ì„œ ìµœê·¼ ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸ì™€ ë³¸ì¸ ê¸°ì—¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                if lang_code == "KOREAN"
                else f"For the {job} role, describe your most recent project and your specific contribution."
            )

        # âœ… ìƒíƒœ ì—…ë°ì´íŠ¸
        seq = int(state.seq or 1)
        state.seq = seq
        if seq == 1:
            reset_interview(interviewId)

        save_question(
            interviewId,
            seq,
            question,
            job=state.job,
            level=state.level,
            language=state.language,
            topic=state.topic,    # âœ… í•­ìƒ state ê°’
            aspect=state.aspect,   # âœ… í•­ìƒ state ê°’
            subtype=current_subtype
        )

        state.question = question
        state.questions.append(question)
        state.step = (state.step or 0) + 1

        if state.topic:
            state.topics[idx]["asked"] += 1
            state.last_question_for_dynamic = question

        # ì¢…ë£Œ ì¡°ê±´ ì²˜ë¦¬
        if getattr(state, "last_label", None) == "terminate":
            if state.topics and state.current_topic_index < len(state.topics):
                print(f"ğŸ›‘ terminate ì‹ í˜¸ ê°ì§€ â†’ '{state.topics[state.current_topic_index]['name']}' ì¢…ë£Œ, ë‹¤ìŒ í† í”½ìœ¼ë¡œ ì´ë™")
                state.topics[state.current_topic_index]["asked"] = state.topics[state.current_topic_index].get("max_questions", 1)
                state.current_topic_index += 1
                state.last_label = None
                if state.current_topic_index >= len(state.topics):
                    state.keepGoing = False
                    return state

        cnt = int(state.count or 0)
        if cnt > 0 and seq >= cnt:
            state.keepGoing = False

        print("âœ… [first_question_node] ìµœì¢… ì§ˆë¬¸:", state.question)
        return state

    except Exception as e:
        print("âŒ [first_question_node ì˜¤ë¥˜ ë°œìƒ]:", str(e))
        import traceback; traceback.print_exc()
        raise e
#------------------------------------------------------------------------------------------------------------------------------    
def next_question_node(state: InterviewState) -> InterviewState:
    """â¡ï¸ ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ë…¸ë“œ (terminate + max_questions ì²˜ë¦¬ + save_question ê°±ì‹  ë°˜ì˜)"""
    try:
        if isinstance(state, dict):
            state = InterviewState(**state)
        
        topics = getattr(state, "topics", [])
        if not topics:
            state.keepGoing = False
            return state
        
        job = (state.job or "").strip() or "ì›¹ ê°œë°œì"
        lang_code = state.language or "KOREAN"
        lang = "í•œêµ­ì–´" if lang_code == "KOREAN" else "ì˜ì–´"
        prev_q = state.questions[-1] if state.questions else ""
        prev_a = state.last_answer or (state.answer[-1] if state.answer else "")

        # í˜„ì¬ í† í”½/ì¸¡ë©´
        aspect_idx = getattr(state, "aspect_index", 0)
        aspect = state.aspects[aspect_idx % len(state.aspects)] if state.aspects else None
        topic = None
        if state.current_topic_index < len(topics):
            topic = topics[state.current_topic_index]
        print(f"ğŸ§­ INTERVIEW TYPE: {state.interviewType}")
        print(f"ğŸ§­ SELECTED ASPECT: {state.aspect}")
        current_subtype = (getattr(state, "subtype", None) or "").strip()
        if not current_subtype:
            from utils.qa_classify import heuristic_scores
            h = heuristic_scores(f"{prev_q} {prev_a}")
            current_subtype = h["subtype_h"] or "METHOD"
        # --- system í”„ë¡¬í”„íŠ¸ êµ¬ì„± ---
        summary_text = " ".join(item.desc for item in state.resume_summary) if state.resume_summary else ""
        system_prompt = (
            f"ë„ˆëŠ” ì¸ê³µì§€ëŠ¥ ë©´ì ‘ê´€ì´ë‹¤.\n"
            f"ì§€ì›ìì˜ ì§ì „ ë‹µë³€ê³¼ ìê¸°ì†Œê°œì„œ(ì„ íƒ)ë¥¼ ì°¸ê³ í•˜ì—¬ {lang}ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ë¼.\n\n"
            "ì„ í˜¸(ê°•ì œ ì•„ë‹˜):\n"
            "- ì§ì „ ë‹µë³€ì˜ ìš”ì§€ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§ˆ ìˆ˜ ìˆë‹¤ë©´ **í›„ì† ì§ˆë¬¸**ì„ ìš°ì„  ê³ ë ¤í•œë‹¤.\n"
            "- ì´ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤ë©´, **í˜„ì¬ í† í”½ ë‚´ì—ì„œ ë‹¤ë¥¸ ì¸¡ë©´ìœ¼ë¡œ ì „í™˜**í•˜ì—¬ ìƒˆ ì§ˆë¬¸ì„ ë§Œë“ ë‹¤.\n\n"
            "ì¡°ê±´:\n"
            "- êµ¬ì²´ì ì´ê³  ë§¥ë½ ìˆëŠ” ì§ˆë¬¸(1ë¬¸ì¥, ìµœëŒ€ 2ë¬¸ì¥)\n"
            "- ë°”ë¡œ ì§ì „ ì§ˆë¬¸ê³¼ëŠ” í¬ì¸íŠ¸ê°€ ê²¹ì¹˜ì§€ ì•ŠìŒ(ì¤‘ë³µ ê¸ˆì§€)\n"
            "- ë©”íƒ€ í‘œí˜„(ì˜ˆ: 'ì´ì œ ~ì— ëŒ€í•´ ë¬»ê² ìŠµë‹ˆë‹¤') ê¸ˆì§€\n"
        )
        if topic:
            system_prompt += (
                f"\ní˜„ì¬ ì£¼ì œ: {topic['name']}\n"
                f"ì°¸ê³ í•  ìê¸°ì†Œê°œì„œ ìš”ì•½: {summary_text or 'ì—†ìŒ'}\n"
                f"ì°¸ê³  ê´€ì (aspect): {aspect}\n"
                "âš ï¸ ì£¼ì œì™€ ìš”ì•½ì€ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³ , ì§ˆë¬¸ ë¬¸ì¥ì— ì§ì ‘ ë…¸ì¶œí•˜ì§€ ë§ ê²ƒ."
            )

        from langchain_core.prompts import ChatPromptTemplate
        from interview.config import llm

        # âŠ FOLLOWUP í›„ë³´(ë§¥ë½ ì´ì–´ì§ˆ ë•Œ)
        followup_prompt = ChatPromptTemplate.from_messages([
            ("system", system_rule(state)),
            ("system", system_prompt),
            ("human",
             "ì§ë¬´: {job}\n"
             "ì„œë¸Œíƒ€ì… íŒíŠ¸: {subtype}\n"
             "ì§ì „ ì§ˆë¬¸: {prev_q}\n"
             "ì§ì „ ë‹µë³€: {prev_a}\n\n"
             "ìš”ì²­: ê°€ëŠ¥í•œ ê²½ìš°, ìœ„ ë‹µë³€ì˜ ìš”ì§€ë¥¼ ë” ê¹Šì´ íŒŒê³ ë“œëŠ” **í›„ì† ì§ˆë¬¸** 1ê°œë¥¼ ìƒì„±í•˜ë¼.")
        ])

        # â‹ LATERAL í›„ë³´(ê°™ì€ í† í”½ ë‚´ ì¸¡ë©´ ì „í™˜)
        lateral_prompt = ChatPromptTemplate.from_messages([
            ("system", system_rule(state)),
            ("system", system_prompt),
            ("human",
             "ì§ë¬´: {job}\n"
             "ì„œë¸Œíƒ€ì… íŒíŠ¸: {subtype}\n"
             "ì§ì „ ì§ˆë¬¸: {prev_q}\n"
             "ì§ì „ ë‹µë³€: {prev_a}\n\n"
             "ìš”ì²­: ìœ„ ë‹µë³€ì—ì„œ ìì—°ìŠ¤ëŸ½ì§€ ì•Šë‹¤ë©´, **í˜„ì¬ í† í”½(commitment ë“±) ë‚´ì—ì„œ ë‹¤ë¥¸ ì¸¡ë©´(method/impact/stakeholder/risk/standard ì¤‘ í•˜ë‚˜)**ì„ ì„ íƒí•´ ìƒˆë¡œìš´ ì§ˆë¬¸ 1ê°œë¥¼ ìƒì„±í•˜ë¼.")
        ])

        def gen_candidate(prompt):
            res = (prompt | llm).invoke({
                "job": job,
                "prev_q": prev_q,
                "prev_a": prev_a,
                "subtype": current_subtype,
            })
            text = (getattr(res, "content", "") or "").strip()
            return clean_question(text)

        candidates = []
        # ì‹œë„ íšŸìˆ˜ëŠ” ê°€ë³ê²Œ 1~2íšŒë¡œë„ ì¶©ë¶„
        for _ in range(2):
            candidates.append(("FOLLOWUP", gen_candidate(followup_prompt)))
            candidates.append(("LATERAL",  gen_candidate(lateral_prompt)))

        # ì¤‘ë³µ/ìœ ì‚¬ ì œê±° + ìŠ¤ì½”ì–´ë§(ì†Œí”„íŠ¸)
        from utils.chroma_qa import get_similar_question
        best_q, best_kind, best_score = None, None, -1.0

        for kind, cand in candidates:
            if not cand or len(cand) < 5:
                continue

            # ì§ì „ ì§ˆë¬¸/ì½”í¼ìŠ¤ì™€ì˜ ì¤‘ë³µ ë°©ì§€
            check = get_similar_question(
                state.interviewId, cand, k=3, min_similarity=0.75,
                verify_all=True, subtype=current_subtype, job=state.job
            )
            if check.get("similar"):
                continue

            # ê°„ë‹¨ ìŠ¤ì½”ì–´: (a) ì ë‹¹í•œ ì—°ê³„ì„± + (b) ì§ì „ ì§ˆë¬¸ê³¼ì˜ ì¤‘ë³µ ë‚®ìŒ
            # ì—°ê³„ì„±: prev_aì™€ì˜ í† í°/í‚¤ì›Œë“œ ê²¹ì¹¨ ì •ë„(ë„ˆë¬´ ë†’ì•„ë„ ë°˜ë³µ ê²½í–¥ â†’ ìƒí•œ)
            from utils.question_filter import lexical_overlap_score, cosine_similarity_score
            link = 0.6*lexical_overlap_score(prev_a, cand) + 0.4*cosine_similarity_score(prev_a, cand)
            # ì¤‘ë³µ íšŒí”¼: prev_qì™€ì˜ ìœ ì‚¬ë„ëŠ” ë‚®ì„ìˆ˜ë¡ ê°€ì‚°
            dup_q = cosine_similarity_score(prev_q, cand)
            score = (min(link, 0.8)) - (0.5*max(0.0, dup_q - 0.6))  # ì†Œí”„íŠ¸í•œ í¸í–¥

            # FOLLOWUPì— ì‚´ì§ ê°€ì¤‘ì¹˜(+0.05) â†’ â€œì„ í˜¸â€ë§Œ ì£¼ê³  â€œê°•ì œâ€ëŠ” ì•„ë‹˜
            if kind == "FOLLOWUP":
                score += 0.05

            if score > best_score:
                best_q, best_kind, best_score = cand, kind, score

        final_q = best_q
        if not final_q:
            # í´ë°±: í˜„ì¬ aspect ê¸°ë°˜ ê¸°ë³¸ ì§ˆë¬¸(ê°•ì œ ì•„ë‹˜)
            fb_list = FALLBACK_POOL.get(state.aspects[state.aspect_index], [])
            final_q = fb_list[0] if fb_list else (
                "ë°©ê¸ˆ ì„¤ëª…í•˜ì‹  ë‚´ìš©ì—ì„œ **ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë˜ ë°©ë²• í•œ ê°€ì§€**ë¥¼ ì˜ˆë¡œ ë“¤ì–´ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ì–´ìš”?"
            )
            best_kind = "FALLBACK"

        print(f"âœ… [ì„ ì •] kind={best_kind} score={best_score:.3f} q={final_q}")

        # ìƒíƒœ ì—…ë°ì´íŠ¸(ë©”ëª¨ë¦¬)
        state.question = final_q
        state.questions.append(final_q)

        # ì €ì¥ ì§ì „ ë³´ì •ë“¤(ë¹ˆ subtype ë°©ì§€, topic ì¼ê´€í™”)
        state.subtype = (getattr(state, "subtype", None) or current_subtype or "METHOD")
        final_topic_name = topic["name"] if topic else (state.topic or None)

        # âš ï¸ ì±„íƒ í›„ 'í•œ ë²ˆë§Œ' ì €ì¥(í›„ë³´ ë‹¨ê³„ ì €ì¥ ê¸ˆì§€)
        from utils.chroma_qa import save_question
        save_question(
            state.interviewId,
            state.seq + 1,
            state.question,
            job=state.job,
            level=state.level,
            language=state.language,
            topic=final_topic_name,
            aspect=aspect,
            # subtype í•„ë“œê°€ ìŠ¤í‚¤ë§ˆì— ìˆìœ¼ë©´ ì—¬ê¸°ì— í•¨ê»˜ ì €ì¥ ê°€ëŠ¥:
            # subtype=state.subtype,
        )

        # (ì´í•˜ terminate / max_questions ì „í™˜ ë¡œì§, ì¹´ìš´í„° ì¦ê°€ëŠ” ê¸°ì¡´ëŒ€ë¡œ)
        if getattr(state, "last_label", None) == "terminate":
            print(f"ğŸ›‘ terminate â†’ '{topics[state.current_topic_index]['name']}' ì¢…ë£Œ, ë‹¤ìŒ í† í”½")
            state.topics[state.current_topic_index]["asked"] = topics[state.current_topic_index].get("max_questions", 1)
            state.current_topic_index += 1
            state.bridge_done = False
            state.last_label = None
            if state.current_topic_index < len(topics):
                state.topic = topics[state.current_topic_index]["name"]
                state.aspect = state.aspects[state.aspect_index % len(state.aspects)] if state.aspects else None
                print(f"ğŸ“Œ [next_question_node] í† í”½ ì „í™˜ ì™„ë£Œ â†’ {state.topic}")
            else:
                state.keepGoing = False
                return state

        elif topic and topic.get("asked", 0) + 1 >= topic.get("max_questions", 3):
            print(f"ğŸ›‘ '{topic['name']}' í† í”½ ì§ˆë¬¸ {topic.get('asked', 0)+1}ê°œ ì™„ë£Œ â†’ ë‹¤ìŒ í† í”½")
            state.current_topic_index += 1
            state.bridge_done = False
            if state.current_topic_index < len(topics):
                state.topic = topics[state.current_topic_index]["name"]
                state.aspect = state.aspects[state.aspect_index % len(state.aspects)] if state.aspects else None
                print(f"ğŸ“Œ [next_question_node] í† í”½ ì „í™˜ ì™„ë£Œ â†’ {state.topic}")
                return next_question_node(state)
            else:
                state.keepGoing = False
                return state

        if topic:
            topic["asked"] = topic.get("asked", 0) + 1
        state.aspect_index = (aspect_idx + 1) % len(state.aspects)

        # ì¢…ë£Œ ì¡°ê±´ì€ ê¸°ì¡´ ê·¸ëŒ€ë¡œ
        if state.count and len(state.questions) > state.count:
            state.keepGoing = False
        elif not state.count and topics:
            if all(t["asked"] >= t.get("max_questions", 1) for t in topics):
                state.keepGoing = False
        elif not state.count and not topics:
            if sum(1 for a in state.answer if a == "terminate") >= 2:
                state.keepGoing = False
            elif len(state.questions) >= 10:
                state.keepGoing = False

    except Exception as e:
        print("âŒ [next_question_node ì˜ˆì™¸]:", str(e))
        import traceback; traceback.print_exc()
        state.keepGoing = False

    state.step += 1
    return state
