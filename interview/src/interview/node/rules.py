from langchain_core.prompts import ChatPromptTemplate
from typing import Literal
import json, re, dirtyjson
from json_repair import repair_json

# ====================================================
# ğŸ”¹ ì–¸ì–´ ê²€ì¦ / ì •ê·œí™” ìœ í‹¸
# ====================================================

_HANGUL = r"[ê°€-í£]"
_LATIN  = r"[A-Za-z]"
_CJK    = r"[\u4E00-\u9FFF\u3400-\u4DBF]"   # í•œì
_JP     = r"[\u3040-\u30FF]"

def _ratio(text: str, pattern: str) -> float:
    if not text:
        return 0.0
    total = len(re.findall(r"\S", text))
    hits  = sum(len(m) for m in re.findall(pattern, text))
    return hits / max(total, 1)

def validate_language_text(text: str, target: Literal["KOREAN", "ENGLISH"]) -> bool:
    """í…ìŠ¤íŠ¸ê°€ ì§€ì • ì–¸ì–´ ê·œì¹™ì„ ë”°ë¥´ëŠ”ì§€ ê²€ì¦"""
    hangul = _ratio(text, _HANGUL)
    latin  = _ratio(text, _LATIN)
    cjk    = _ratio(text, _CJK)
    jp     = _ratio(text, _JP)
    if target == "KOREAN":
        return (hangul >= 0.80) and ((cjk + jp + latin) <= 0.20)
    else:
        return (latin >= 0.80) and ((cjk + jp) <= 0.20)

def normalize_text(llm, text: str, target: Literal["KOREAN", "ENGLISH"], nounify: bool=False) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë‚˜ ì˜ì–´ë¡œ ì •ê·œí™” (í† í”½ìš©ì´ë©´ ëª…ì‚¬í˜•ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥)"""
    if target == "ENGLISH":
        sys_rule = "Use English only. Keep the meaning. Output body only."
        if nounify:
            sys_rule += " Convert into a noun phrase (not a question)."
        user = "Rewrite in English only:\n" + (text or "")
    else:
        sys_rule = "ì˜¤ì§ í•œêµ­ì–´ë§Œ ì‚¬ìš©. ì˜ë¯¸ ìœ ì§€. ë³¸ë¬¸ë§Œ ì¶œë ¥."
        if nounify:
            sys_rule += " ëª…ì‚¬êµ¬ë¡œ ë³€í™˜. ì§ˆë¬¸ë¬¸/ì¡°ì‚¬/ì–´ë¯¸ ì œê±°."
        user = "í•œêµ­ì–´ë¡œ ë‹¤ì‹œ ì“°ê¸°:\n" + (text or "")

    # í† í° ì ˆì•½: ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
    if len(user) > 350:
        user = user[:350].rsplit(" ", 1)[0] + "..."

    try:
        resp = (
            ChatPromptTemplate.from_messages([
                ("system", sys_rule),
                ("user", "{u}")
            ]) | llm.bind(max_tokens=60, temperature=0)
        ).invoke({"u": user})
        return getattr(resp, "content", str(resp)).strip()
    except Exception:
        return text or ""


# ====================================================
# ğŸ”¹ í† í”½ ì •ê·œí™”
# ====================================================

def normalize_topic_str(text: str) -> str:
    """ë¬¸ì¥í˜• í† í”½ì„ ëª…ì‚¬í˜• í‚¤ì›Œë“œë¡œ ì •ê·œí™”"""
    t = text.strip()
    t = re.sub(r'ì—\s*(ëŒ€í•œ|ê´€í•œ|ëŒ€í•´)', ' ', t)
    t = re.sub(r'(ì´|ê°€)?\s*ìˆëŠ”ì§€$', '', t)
    t = re.sub(r'(í•˜ëŠ”ì§€|í–ˆëŠ”ì§€|ë ì§€|ë ê¹Œ)$', '', t)
    t = re.sub(r'(ì¸ê°€ìš”|ì¸ê°€|ì´ëƒ)$', '', t)
    return re.sub(r'\s+', ' ', t).strip()


# ====================================================
# ğŸ”¹ JSON íŒŒì‹± (LLM ì¶œë ¥ ë³´ì • í¬í•¨)
# ====================================================

def safe_parse_json_from_llm(content: str) -> dict:
    print("ğŸ“¨ [LLM ì‘ë‹µ ì›ë¬¸]:", content)
    
    # ë¬´ì¡°ê±´ ì´ˆê¸°í™”
    cleaned = str(content).strip().replace("```json", "").replace("```", "").strip()

    # âœ… ìë™ ê´„í˜¸ ë³´ì •
    if cleaned.count("{") > cleaned.count("}"):
        cleaned += "}" * (cleaned.count("{") - cleaned.count("}"))

    try:
        parsed = json.loads(cleaned)
        if isinstance(parsed, dict):
            print("âœ… [JSON íŒŒì‹± ì„±ê³µ]:", parsed)
            return parsed
    except Exception as e:
        print("âŒ [JSON íŒŒì‹± ì‹¤íŒ¨ - 1ì°¨]:", str(e))

    # âœ… fallback: dirtyjson
    try:
        parsed = dirtyjson.loads(cleaned)
        if isinstance(parsed, dict):
            print("âœ… [JSON íŒŒì‹± ì„±ê³µ - dirtyjson]:", parsed)
            return parsed
    except Exception as e:
        print("âŒ [JSON íŒŒì‹± ì‹¤íŒ¨ - dirtyjson]:", str(e))

    # ì‹¤íŒ¨í•˜ë©´ ë¹ˆ dict
    return {}



# ====================================================
# ğŸ”¹ ì¸í„°ë·° ê·œì¹™ ë§¤í•‘
# ====================================================

TYPE_RULE = {
    "TECHNICAL": "- êµ¬ì²´ì ì¸ ê¸°ìˆ ì  ë°©ë²•, ê³¼ì •, ê²°ê³¼, ë¬¸ì œ í•´ê²° ê²½í—˜ì— ì§‘ì¤‘í•  ê²ƒ. ì¸ì„±/ê°€ì¹˜ê´€ ê´€ë ¨ ì§ˆë¬¸ ê¸ˆì§€.",
    "PERSONALITY": "- ì§€ì›ìì˜ ì„±ê²©, í–‰ë™, ë™ê¸°, íƒœë„, í˜‘ì—… ë°©ì‹ì— ì´ˆì ì„ ë§ì¶œ ê²ƒ. ì¶”ìƒì  í‘œí˜„(ê°€ì¹˜ê´€, ì„±ì¥ ê°€ëŠ¥ì„±) ê¸ˆì§€.",
    "MIXED": "- ê¸°ìˆ ê³¼ ì¸ì„± ì§ˆë¬¸ì„ ê· í˜• ìˆê²Œ ì„ë˜ ë™ì¼ ìœ í˜•ë§Œ ë°˜ë³µí•˜ì§€ ë§ ê²ƒ."
}

LEVEL_RULE = {
    "í•˜": "- ì‰¬ìš´ ì§ˆë¬¸. ë¶€ë‹´ ì—†ëŠ” ê²½í—˜ ì¤‘ì‹¬. ì˜ˆ: 'ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” í”„ë¡œì íŠ¸ëŠ” ë¬´ì—‡ì´ì—ˆë‚˜ìš”?'",
    "ì¤‘": "- ì‹¤ì œ ìƒí™© ëŒ€ì²˜/ì ìš©ì„ ë¬»ëŠ” ì§ˆë¬¸. ì˜ˆ: 'íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ìˆì—ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?'",
    "ìƒ": "- ì‹¬ì¸µì ì´ê³  ì••ë°• ìˆëŠ” ì§ˆë¬¸. ì˜ˆ: 'í”„ë¡œì íŠ¸ ì‹¤íŒ¨ ì›ì¸ê³¼ ë³¸ì¸ì˜ ì±…ì„ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ë‚˜ìš”?'"
}

LANG_RULE = {
    "KOREAN": (
        "- ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ ì§ˆë¬¸ í•˜ë‚˜ë¿. "
        "- í‰ì„œë¬¸(~ë‹¤, ~ìˆë‹¤) ê¸ˆì§€, ì§ˆë¬¸ ì–´ë¯¸(~ë‚˜ìš”?, ~ìŠµë‹ˆê¹Œ?) í•„ìˆ˜."
    ),
    "ENGLISH": (
        "- Output must be in English only. "
        "- Must be a single interview question ending with '?'. "
        "- No prefaces, no numbering, no explanations."
    )
}


# ====================================================
# ğŸ”¹ system_rule ìƒì„±ê¸°
# ====================================================

def system_rule(state) -> str:
    """ë©´ì ‘ ìœ í˜• + ë‚œì´ë„ + ì–¸ì–´ì— ë§ëŠ” system prompt ìƒì„±"""
    language = getattr(state, "language", "KOREAN")
    interviewType = getattr(state, "interviewType", "MIXED")
    career = getattr(state, "career", "ì‹ ì…")
    level = getattr(state, "level", "ì¤‘")

    base = "ë„ˆëŠ” ë©´ì ‘ê´€ì´ë‹¤. " if language == "KOREAN" else "You are an interviewer. "
    base += "- ì¶œë ¥ì€ ë°˜ë“œì‹œ ì§ˆë¬¸ í•˜ë‚˜ë¿ì´ë‹¤. ë‹µë³€, í•´ì„¤, ì„¤ëª…, ë©”íƒ€ ë¬¸êµ¬ ê¸ˆì§€. "
    base += TYPE_RULE.get(interviewType, "")
    base += LEVEL_RULE.get(level, "")
    base += LANG_RULE.get(language, "")

    # ê²½ë ¥ êµ¬ë¶„
    if career == "ì‹ ì…":
        base += " ì‹ ì…ì´ë¯€ë¡œ í•™ìŠµ íƒœë„, ì„±ì¥ ê°€ëŠ¥ì„±, ì ì‘ë ¥ì— ì´ˆì ì„ ë§ì¶°ë¼."
    elif career in ["ê²½ë ¥", "ê²½ë ¥ì§"]:
        base += " ê²½ë ¥ì§ì´ë¯€ë¡œ ì„±ê³¼, ë¦¬ë”ì‹­, ë¬¸ì œ í•´ê²° ê²½í—˜ì— ì´ˆì ì„ ë§ì¶°ë¼."

    return base


# ====================================================
# ğŸ”¹ ì§ˆë¬¸ í›„ì²˜ë¦¬
# ====================================================

def validate_question(q: str, lang: str = "KOREAN") -> bool:
    """ì§ˆë¬¸ì´ ìì—°ìŠ¤ëŸ¬ìš´ ì–´ë¯¸ ê·œì¹™ì„ ë”°ë¥´ëŠ”ì§€ í™•ì¸"""
    q = q.strip()
    if lang == "KOREAN":
        endings = ["ë‚˜ìš”?", "ìŠµë‹ˆê¹Œ?", "í• ê¹Œìš”?", "ìˆë‚˜ìš”?", "ìˆìŠµë‹ˆê¹Œ?", "ë¬´ì—‡ì¸ê°€ìš”?", "ì–´ë–»ê²Œ ìƒê°í•˜ë‚˜ìš”?"]
        return any(q.endswith(end) for end in endings)
    else:
        return q.endswith("?") and q.lower().split()[0] in [
            "what", "why", "how", "when", "where",
            "do", "does", "did", "can", "could", "would"
        ]

def clean_question(q: str) -> str:
    """ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬, ë©”íƒ€ì„¤ëª… ì œê±°"""
    q = q.strip()
    q = re.sub(r'^(?:\d+|Q\d+|ì§ˆë¬¸)[:\.\-\s]*', '', q, flags=re.IGNORECASE)  # ë²ˆí˜¸ ì œê±°
    q = re.sub(r'.*ì— ëŒ€í•œ ì§ˆë¬¸(ì…ë‹ˆë‹¤|ì…ë‹ˆë‹¤\.)', '', q)                   # "ì— ëŒ€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤" ì œê±°
    q = q.strip('"â€œâ€')
    return q
