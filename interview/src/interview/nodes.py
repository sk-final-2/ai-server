from interview.model import InterviewState
from langchain_core.prompts import ChatPromptTemplate
from interview.chroma_qa import get_similar_qa, save_qa_pair
from langchain_openai import ChatOpenAI
from typing import Union
import os, json
from dotenv import load_dotenv

load_dotenv("src/interview/.env")

def safe_parse_json_from_llm(content: str) -> dict:
    print("ğŸ“¨ [LLM ì‘ë‹µ ì›ë¬¸]:", content)
    
    try:
        cleaned = content.strip().replace("```json", "").replace("```", "").strip()
        print("ğŸ§¼ [í´ë¦°ëœ ë¬¸ìì—´]:", cleaned)

        parsed = json.loads(cleaned)

        if isinstance(parsed, dict):
            print("âœ… [JSON íŒŒì‹± ì„±ê³µ]:", parsed)
            return parsed
        else:
            print("âŒ [íŒŒì‹±ì€ ëì§€ë§Œ dict ì•„ë‹˜]:", parsed)
            return {}

    except Exception as e:
        print("âŒ [JSON íŒŒì‹± ì˜ˆì™¸]:", str(e))
        return {}
type_rule_map = {
    "tech": "- ê¸°ìˆ ì ì¸ ê¹Šì´ë¥¼ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ í¬í•¨í•  ê²ƒ",
    "behavior": "- í–‰ë™ ë° ê°€ì¹˜ê´€ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ í¬í•¨í•  ê²ƒ",
    "mixed": "- ê¸°ìˆ ê³¼ ì¸ì„±ì„ ëª¨ë‘ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ í¬í•¨í•  ê²ƒ"
}
def get_type_rule(state):
    return type_rule_map.get(state.interviewType, "")

def get_Language_rule(lang: str):
    if lang.lower() == "KOREAN":
        return "ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”."
    elif lang.lower() == "ENGLISH":
        return "Output must be written in English only."
    else:
        return ""
    
# LLM ì„¤ì •       
llm = ChatOpenAI(
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    base_url="https://api.groq.com/openai/v1",
    model="llama3-8b-8192",
    temperature=0.7
)
def router_node(state: InterviewState) -> str:
    if not state.answer:
        print("ğŸ§­ [router_node] ì²« ì§ˆë¬¸ ìƒì„± íë¦„")
        return "first_question"
    else:
        print("ğŸ§­ [router_node] ë‹µë³€ ë¶„ì„ íë¦„")
        return "answer"
    
def set_options_node(state: InterviewState) -> InterviewState:
    """ğŸ›  ë©´ì ‘ ì˜µì…˜(Language, level, count, interviewType) í™•ì • ë…¸ë“œ"""
    if isinstance(state, dict):
        state = InterviewState(**state)

    print("\n======================")
    print("âš™ï¸ [set_options_node] ì˜µì…˜ ì„¤ì • ì‹œì‘")
    print(f"ì…ë ¥ Language: {state.Language}, level: {state.level}, count: {state.count}, interviewType: {state.interviewType}")
    print("======================")

    # ê¸°ë³¸ê°’ ì²˜ë¦¬ (ëª…ì„¸ì„œ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    if not state.Language:
        state.Language = "KOREAN"        # ëª…ì„¸ì„œ ê¸°ì¤€
    if not state.level:
        state.level = "ì¤‘"               # ëª…ì„¸ì„œ ê¸°ì¤€ (ìƒ/ì¤‘/í•˜)
    if state.count is None:
        state.count = 0                  # 0ì´ë©´ ë™ì  ëª¨ë“œ
    if not state.interviewType:
        state.interviewType = "MIXED"   # ê¸°ë³¸ê°’ (ëª…ì„¸ì„œì— ë§ì¶° ì‚¬ìš©)

    # ì ê¸ˆ
    state.options_locked = True

    print(f"âœ… ìµœì¢… Language: {state.Language}, level: {state.level}, count: {state.count}, interviewType: {state.interviewType}")
    return state

def build_prompt(state: InterviewState):
    lang_sys = "í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”." if state.Language == "KOREAN" else "Ask in English."
    diff_rule = {
        "í•˜": "ê°œë… í™•ì¸ ìœ„ì£¼ë¡œ, ìš©ì–´ë¥¼ í’€ì–´ì„œ ë¬»ê³  íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.",
        "ì¤‘": "ì§ë¬´ ê´€ë ¨ êµ¬ì²´ ì§ˆë¬¸ê³¼ ê°„ë‹¨í•œ ê¼¬ë¦¬ì§ˆë¬¸ì„ í¬í•¨í•˜ì„¸ìš”.",
        "ìƒ": "ëª¨í˜¸ì„± í—ˆìš©, ë°˜ë¡€Â·íŠ¸ë ˆì´ë“œì˜¤í”„, ì‹œìŠ¤í…œ ì„¤ê³„/ê¹Šì€ CS ì§ˆë¬¸ì„ ìš°ì„ í•˜ì„¸ìš”."
    }[state.level]
    system = f"{lang_sys}\nì§ˆë¬¸ ë‚œì´ë„: {state.level}\nê·œì¹™: {diff_rule}"
    return ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "{context}")
    ])
    
def first_question_node(state: InterviewState) -> InterviewState:
    print("âœ… state.raw:", state.model_dump())
    """ğŸ¯ ì²« ì§ˆë¬¸ ìƒì„± ë…¸ë“œ"""
    try:
        # âœ… Pydantic ê°ì²´ ë³´ì¥
        if isinstance(state, dict):
            state = InterviewState(**state)

        print("\n======================")
        print("ğŸ¯ [first_question_node] ì§„ì…")
        print(f"ğŸ’¼ ì§€ì› ì§ë¬´: {state.job}")
        print(f"ğŸ“„ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {state.text[:100] if state.text else state.resume[:100] if state.resume else 'âŒ ì—†ìŒ'}")
        print("======================")

        # âœ… ì§ë¬´ ê¸°ë³¸ê°’ ì²˜ë¦¬
        if not state.job or state.job == "string":
            print("âš ï¸ [ê²½ê³ ] ì§ë¬´ ì •ë³´ ëˆ„ë½ â†’ ê¸°ë³¸ê°’ 'ì›¹ ê°œë°œì' ì ìš©")
            state.job = "ì›¹ ê°œë°œì"

        # âœ… ì´ë ¥ì„œ í…ìŠ¤íŠ¸ í†µí•©
        resume_text = state.text or state.resume or ""
        if not resume_text:
            raise ValueError("âŒ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŒ")

        prompt = ChatPromptTemplate.from_messages([
            ("system", f"""
                ë‹¹ì‹ ì€ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
                ì•„ë˜ ì§€ì›ìì˜ ìê¸°ì†Œê°œì„œì™€ ê²½ë ¥ ì—¬ë¶€ë¥¼ ë°”íƒ•ìœ¼ë¡œ
                ë©´ì ‘ì—ì„œ ì‹œì‘í•  ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ { 'í•œêµ­ì–´' if state.Language.lower() == 'KOREAN' else 'ì˜ì–´' }ë¡œë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ìƒì„±í•˜ì„¸ìš”.
                - ì§ˆë¬¸ì€ í•œ ë¬¸ì¥, ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ.
                {get_type_rule(state)}
                {get_Language_rule(state.Language)}

                ì§€ì› ì§ë¬´: {{job}}
                ê²½ë ¥ ì—¬ë¶€: {{career}}
                ì§€ì›ìì˜ ìê¸°ì†Œê°œì„œ:
                {{resume}}
                """)   
                ])
        chain = prompt | llm

        # âœ… LLM ì‹¤í–‰
        print("ğŸ§  [LLM ìš”ì²­ ì‹œì‘]")
        response = chain.invoke({"job": state.job, "career": state.career, "resume": resume_text})
        question = response.content.strip() if hasattr(response, "content") else str(response).strip()

        print("ğŸ“¨ [ìƒì„±ëœ ì§ˆë¬¸]:", question)
        if not question:
            raise ValueError("âŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (ë¹ˆ ì‘ë‹µ)")

        # âœ… ìƒíƒœ ì—…ë°ì´íŠ¸
        state.questions.append(question)
        save_qa_pair(question, "")
        state.step += 1
        # âœ… ì¢…ë£Œ íŒë‹¨
        if state.count and len(state.questions) >= state.count:
            state.is_finished = True
        elif not state.count and len(state.questions) >= 20:
            state.is_finished = True

        return state

    except Exception as e:
        print("âŒ [first_question_node ì˜¤ë¥˜ ë°œìƒ]:", str(e))
        import traceback
        traceback.print_exc()
        raise e
    

def answer_node(state: InterviewState) -> Union[InterviewState, None]:
    """ë‹µë³€ ìˆ˜ì§‘ ë…¸ë“œ - ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦¬ëŠ” ìƒíƒœ"""

    if isinstance(state, dict):
        state_obj = InterviewState(**state)
    else:
        state_obj = state

    print("âœï¸ [answer_node] ì‚¬ìš©ì ë‹µë³€ ëŒ€ê¸° ì¤‘...")
    print(f"â“ í˜„ì¬ ì§ˆë¬¸: {state_obj.questions[-1] if state_obj.questions else 'None'}")
    print(f"ğŸ“¦ [answer_node ë¦¬í„´ íƒ€ì…]: {type(state_obj)} / ê°’: {state_obj}")

    # â— ë‹µë³€ì´ ì—†ìœ¼ë©´ FSM ì¢…ë£Œ (ë‚˜ì¤‘ì— ì´ì–´ì„œ ì‹¤í–‰í•´ì•¼ í•¨)
    if not state_obj.last_answer:
        print("ğŸ›‘ [answer_node] ë‹µë³€ì´ ì—†ì–´ FSM ì¢…ë£Œ â†’ ì™¸ë¶€ ì…ë ¥ ëŒ€ê¸°")
        return None
     
    question = state_obj.questions[-1] if state_obj.questions else "ì§ˆë¬¸ ì—†ìŒ"
    save_qa_pair(question, state_obj.last_answer)


    # âœ… ë‹µë³€ì´ ìˆëŠ” ê²½ìš°: ì •ìƒ ì§„í–‰
    print("âœ… [answer_node] ë‹µë³€ ìˆ˜ì‹ ë¨ â†’ ë‹¤ìŒ ë‹¨ê³„ë¡œ")
    state_obj.answer.append(state_obj.last_answer)
    state_obj.step += 1
    return state_obj

def analyze_node(state: InterviewState) -> InterviewState:
    """ğŸ§  ë‹µë³€ ë¶„ì„ ë…¸ë“œ"""
    try:
        # âœ… Pydantic ëª¨ë¸ ë³´ì¥
        if isinstance(state, dict):
            state = InterviewState(**state)

        print("\n======================")
        print("ğŸ” [analyze_node] ì§„ì…")
        print(f"ğŸ“ í˜„ì¬ step: {state.step}")
        print("======================")

        # âœ… ë¶„ì„í•  ë‹µë³€ ê°€ì ¸ì˜¤ê¸°
        answer = state.last_answer or (state.answer[-1] if state.answer else "")
        if not answer:
            print("âš ï¸ [ê²½ê³ ] ë¶„ì„í•  ë‹µë³€ì´ ì—†ìŒ")
            state.last_analysis = {"comment": "ë‹µë³€ì´ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            state.step += 1
            return state

        print("ğŸ“ [ë¶„ì„ ëŒ€ìƒ ë‹µë³€]:", answer[:100], "...")

        # âœ… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë„ˆëŠ” ë©´ì ‘ í‰ê°€ìì…ë‹ˆë‹¤. ì•„ë˜ì˜ ë‹µë³€ì„ ë¶„ì„í•´ì„œ 'ì˜í•œ ì ', 'ê°œì„ ì´ í•„ìš”í•œ ì ', 'ì ìˆ˜(0~100)'ë¥¼ ê°ê° í•˜ë‚˜ì”© ë„ì¶œí•˜ì„¸ìš”. ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ë§ê³ ,
í˜•ì‹ì€ ê¼­ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ í•œêµ­ì–´ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì˜í•œ ì ì´ ì—†ì–´ë„ ì‘ì„±í•´ì£¼ì„¸ìš”.:
{{
  "good": "ì˜í•œ ì ",
  "bad": "ê°œì„ ì´ í•„ìš”í•œ ì ",
  "score": ì ìˆ˜ìˆ«ì
}}
"""),
            ("human", "ë‹µë³€: {answer}")
        ])
        chain = prompt | llm

        # âœ… LLM ë¶„ì„ ìš”ì²­
        print("ğŸ” [LLM ìš”ì²­ ì‹œì‘]")
        response = chain.invoke({"answer": answer})
        print("ğŸ“¨ [LLM ì‘ë‹µ ì›ë¬¸]:", response.content)

        # âœ… JSON íŒŒì‹± ì‹œë„
        analysis_json = safe_parse_json_from_llm(response.content)
        if not analysis_json or not isinstance(analysis_json, dict):
            print("âŒ [ì˜ˆì™¸ ê²½ê³ ] ë¶„ì„ ê²°ê³¼ê°€ None ë˜ëŠ” dict ì•„ë‹˜ â†’", analysis_json)
            analysis_json = {}
        

        # âœ… ìƒíƒœì— ì €ì¥
        state.last_analysis = {
            "good": analysis_json.get("good", ""),
            "bad": analysis_json.get("bad", ""),
            "score": analysis_json.get("score", 0)
        }

    except Exception as e:
        print("âŒ [analyze_node ì˜¤ë¥˜]:", str(e))
        import traceback
        traceback.print_exc()
        state.last_analysis = {"comment": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

    state.step += 1
    return state


def next_question_node(state: InterviewState) -> InterviewState:
    """â¡ï¸ ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ë…¸ë“œ (ìœ ì‚¬ë„ í•„í„° í¬í•¨)"""
    question_prompt = ChatPromptTemplate.from_messages([
    ("system", f"""
ë„ˆëŠ” ì¸ê³µì§€ëŠ¥ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì§€ì›ìê°€ ì œì¶œí•œ ìê¸°ì†Œê°œì„œì™€ ì§ì „ì— í•œ ë‹µë³€ì„ ì°¸ê³ í•˜ì—¬
ë‹¤ìŒì— ì´ì–´ì§ˆ ë©´ì ‘ ì§ˆë¬¸ì„ { 'í•œêµ­ì–´' if state.Language.lower() == 'KOREAN' else 'ì˜ì–´' }ë¡œë§Œ ìƒì„±í•˜ì„¸ìš”.

ì¡°ê±´:
- êµ¬ì²´ì ì´ê³  ë§¥ë½ ìˆëŠ” ì§ˆë¬¸
- ì´ì „ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•˜ì§€ ì•ŠìŒ
- ì§ë¬´ ë˜ëŠ” ì¸ì„± ê´€ë ¨ ì§ˆë¬¸ ìœ„ì£¼
- ë„ˆë¬´ í¬ê´„ì ì¸ ì§ˆë¬¸ ì§€ì–‘
- í˜•ì‹ì€ ì§ˆë¬¸ ë¬¸ì¥ë§Œ ì¶œë ¥
{get_Language_rule(state.Language)}
{get_type_rule(state)}
"""),
    ("human", "{text}")
])
    try:
        if isinstance(state, dict):
            state = InterviewState(**state)

        if len(state.questions) >= state.count:
            state.is_finished = True
            state.step += 1
            print("ğŸ ì§ˆë¬¸ ì¢…ë£Œ")
            return state

        previous_answer = state.last_answer or (state.answer[-1] if state.answer else "")
        resume_text = state.text or ""
        print("ğŸ“ [LLM ì…ë ¥ ì¤€ë¹„] ë‹µë³€:", previous_answer)
        print("ğŸ“„ [LLM ì…ë ¥ ì¤€ë¹„] ìê¸°ì†Œê°œì„œ ìˆìŒ ì—¬ë¶€:", bool(resume_text))

        next_q = None
        attempt = 0
        max_attempts = 3

        while attempt < max_attempts:
            try:
                type_rule_value = get_type_rule(state)
                result = (question_prompt | llm).invoke({
                    "text": state.text,
                    "answer": state.answer,
                    "type_rule": type_rule_value
                })
                candidate_q = result.content.strip()
                print(f"ğŸ§ª [ì‹œë„ {attempt+1}] í›„ë³´ ì§ˆë¬¸:", candidate_q)

                # âœ… ê¸°ì¡´ ìœ ì‚¬ ì§ˆë¬¸ í™•ì¸
                similar_qas = get_similar_qa(candidate_q, k=1)
                if not similar_qas:
                    print("âœ… ìœ ì‚¬ë„ ë‚®ìŒ â†’ ì§ˆë¬¸ ì±„íƒ")
                    next_q = candidate_q
                    break
                else:
                    print("âŒ ìœ ì‚¬í•œ Q/A ì¡´ì¬ â†’ ì¬ì‹œë„")
                    attempt += 1

            except Exception as e:
                print("âš ï¸ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨:", str(e))
                attempt += 1

        # ğŸ”š ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ ì§ˆë¬¸ì´ë¼ë„ ì‚¬ìš©
        if not next_q:
            next_q = candidate_q if 'candidate_q' in locals() else "ë°©ê¸ˆ ë‹µë³€ì— ëŒ€í•´ ì¢€ ë” ì„¤ëª…í•´ì£¼ì‹œê² ì–´ìš”?"
            print("âš ï¸ ì¬ì‹œë„ ì‹¤íŒ¨ â†’ ë§ˆì§€ë§‰ ì§ˆë¬¸ ì‚¬ìš©:", next_q)

        # âœ… ì§ˆë¬¸ ì¶”ê°€ ë° ìƒíƒœ ê°±ì‹ 
        state.questions.append(next_q)
        print(f"â¡ï¸ ì§ˆë¬¸ {len(state.questions)} ìƒì„± ì™„ë£Œ: {next_q}")
        if state.count and len(state.questions) >= state.count:
            state.is_finished = True
        elif not state.count and len(state.questions) >= 20:
            state.is_finished = True
        
    except Exception as e:
        print("âŒ [next_question_node ì˜ˆì™¸ ë°œìƒ]:", str(e))
        import traceback
        traceback.print_exc()
        state.is_finished = True

    state.step += 1
    return state